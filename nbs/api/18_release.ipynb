{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# release\n",
    "\n",
    "> Auto-generated tagged releases and release notes from GitHub issues\n",
    "- order: 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nbdev.release` provides 3 commands that you can run from your shell to manage your changelog file and git releases:\n",
    "\n",
    "- `nbdev_changelog`: creates a CHANGELOG.md file from closed and labeled GitHub issues\n",
    "- `nbdev_release_git`: tags and creates a release in GitHub for the current version\n",
    "- `nbdev_release_gh`: calls `nbdev_changelog`, lets you edit the result, then pushes to git and calls `nbdev_release_git`\n",
    "\n",
    "It provides 3 futher commands for releasing packages on pypi or conda:\n",
    "\n",
    "- `nbdev_pypi`: Create and upload a pypi installer\n",
    "- `nbdev_conda`: Create and upload a conda installer\n",
    "- `nbdev_release_both`: Create and upload both pypi and conda installers\n",
    "\n",
    "Here's a brief demonstration of how to use the changelog and git release tools in `nbdev.release`. This demo first creates an issue using the [`gh`](https://cli.github.com/) command line tool, and then closes it using `git`; you can also use GitHub's web interface for both of these tasks. (Note that this functionality used to be in a project called `fastrelease`, so in the video the command line tools have different names, starting with `fastrelease_` instead of `nbdev_`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](images/release.svg){width=\"900px\"}](images/release.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need to get a GitHub [personal access token](https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token) if you haven't already. To do so, [click here](https://github.com/settings/tokens/new) and enter \"nbdev\" in the \"Note\" section, and click the `repo` checkbox.\n",
    "\n",
    "Then click \"Generate Token\" at the bottom of the screen, and copy the token (the long string of letters and numbers shown). You can easily do that by clicking the little clipboard icon next to the token.\n",
    "\n",
    "<img alt=\"Copying your token\" width=\"743\" caption=\"Copying your token\" src=\"images/token.png\">\n",
    "\n",
    "It’s easiest to save the token as an environment variable `GITHUB_TOKEN` that can be automatically accessed. We recommend you do this is by adding the following to the end of your `.bashrc` or `.zshrc` file:\n",
    "\n",
    "```bash\n",
    "export GITHUB_TOKEN=xxx\n",
    "```\n",
    "\n",
    "…and then replace the `xxx` with the token you just copied. It will automatically be avaialble whenever you start a new shell (but don’t forget to `source` that file or open a new shell after you change it.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating release notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're ready to create your release notes. These are created in a file called `CHANGELOG.md`. Here's an example of what it creates: [nbdev CHANGELOG](https://github.com/fastai/nbdev/blob/master/CHANGELOG.md).\n",
    "\n",
    "All issues with the label **bug**, **enhancement**, or **breaking** that have been closed in your repo since your last release will be added to the top of this file. If you haven't made any releases before, then all issues with those labels will be included.\n",
    "\n",
    "Therefore, before you create or update `CHANGELOG.md`, go to your GitHub issues page, remove `is:open` from the filter, and label any issues you want included with one of the labels above. When you've done that, you can create or update your release notes by running in your terminal:\n",
    "\n",
    "    nbdev_changelog\n",
    "\n",
    "The titles and bodies of each issue will be added. Open `CHANGELOG.md` in your editor and make any edits that you want, and then commit the file to your repo (remember to `git add` it!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging a release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now tag a release. This will create a tag in GitHub with your current version number in `settings.ini`, and will then make it into a release, using your latest release notes as the description of the release:\n",
    "\n",
    "    nbdev_release_git\n",
    "\n",
    "After you run this, be sure to increment your version number in `settings.ini`. You can either edit it manually, or if you use nbdev it can be done for you by running:\n",
    "\n",
    "    nbdev_bump_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing both (creating release notes, and tagging a release)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete both of the steps above, run:\n",
    "\n",
    "```\n",
    "nbdev_release_gh\n",
    "```\n",
    "\n",
    "See the screencast above for a demonstration of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore.all import *\n",
    "from ghapi.core import *\n",
    "\n",
    "from datetime import datetime\n",
    "import shutil,subprocess\n",
    "\n",
    "from nbdev.doclinks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "GH_HOST = \"https://api.github.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _find_config(cfg_name=\"settings.ini\"):\n",
    "    cfg_path = Path().absolute()\n",
    "    while cfg_path != cfg_path.parent and not (cfg_path/cfg_name).exists(): cfg_path = cfg_path.parent\n",
    "    return Config(cfg_path, cfg_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _issue_txt(issue):\n",
    "    res = '- {} ([#{}]({}))'.format(issue.title.strip(), issue.number, issue.html_url)\n",
    "    if hasattr(issue, 'pull_request'): res += ', thanks to [@{}]({})'.format(issue.user.login, issue.user.html_url)\n",
    "    res += '\\n'\n",
    "    if not issue.body: return res\n",
    "    return res + f\"  - {issue.body.strip()}\\n\"\n",
    "\n",
    "def _issues_txt(iss, label):\n",
    "    if not iss: return ''\n",
    "    res = f\"### {label}\\n\\n\"\n",
    "    return res + '\\n'.join(map(_issue_txt, iss))\n",
    "\n",
    "def _load_json(cfg, k):\n",
    "    try: return json.loads(cfg[k])\n",
    "    except json.JSONDecodeError as e: raise Exception(f\"Key: `{k}` in .ini file is not a valid JSON string: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Release:\n",
    "    def __init__(self, owner=None, repo=None, token=None, **groups):\n",
    "        \"Create CHANGELOG.md from GitHub issues\"\n",
    "        self.cfg = _find_config()\n",
    "        self.changefile = self.cfg.config_path/'CHANGELOG.md'\n",
    "        if not groups:\n",
    "            default_groups=dict(breaking=\"Breaking Changes\", enhancement=\"New Features\", bug=\"Bugs Squashed\")\n",
    "            groups=_load_json(self.cfg, 'label_groups') if 'label_groups' in self.cfg else default_groups\n",
    "        os.chdir(self.cfg.config_path)\n",
    "        owner,repo = owner or self.cfg.user, repo or self.cfg.repo\n",
    "        token = ifnone(token, os.getenv('NBDEV_TOKEN',None))\n",
    "        if not token and Path('token').exists(): token = Path('token').read_text().strip()\n",
    "        token = ifnone(token, os.getenv('GITHUB_TOKEN',None))\n",
    "        if not token: raise Exception('Failed to find token')\n",
    "        self.gh = GhApi(owner, repo, token)\n",
    "        self.groups = groups\n",
    "\n",
    "    def _issues(self, label):\n",
    "        return self.gh.issues.list_for_repo(state='closed', sort='created', filter='all', since=self.commit_date, labels=label)\n",
    "    def _issue_groups(self): return parallel(self._issues, self.groups.keys(), progress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a markdown changelog, first create a `Release` object, optionally passing a mapping from GitHub labels to markdown titles. Put your github token in a file named `token` at the root of your repo.  `Release` attempts to fetch values for arguments from the following locations if not supplied:\n",
    "\n",
    "- **owner:** fetched from the field `user` in `settings.ini`.  This is the owner name of the repository on GitHub. For example for the repo `fastai/fastcore` the owner would be `fastai`.\n",
    "- **repo:** fetched from the field `lib_name` in `settings.ini`.  This is the name of the repository on GitHub.  For example for the repo `fastai/fastcore` the owner would be `fastcore`.\n",
    "- **token:** fetched from a file named `token` at the root of your repo.  Creating a token is discussed in [the setup](https://fastrelease.fast.ai/#Set-up) section.\n",
    "- **groups:** (optional) fetched from the field `label_groups` in `settings.ini`, which is a JSON string.  This is a mapping from label names to titles in your release notes. If not specified, this defaults to:\n",
    "\n",
    "```python\n",
    "{\"breaking\": \"Breaking Changes\", \"enhancement\":\"New Features\", \"bug\":\"Bugs Squashed\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def changelog(self:Release,\n",
    "              debug=False): # Just print the latest changes, instead of updating file\n",
    "    \"Create the CHANGELOG.md file, or return the proposed text if `debug` is `True`\"\n",
    "    if not self.changefile.exists(): self.changefile.write_text(\"# Release notes\\n\\n<!-- do not remove -->\\n\")\n",
    "    marker = '<!-- do not remove -->\\n'\n",
    "    try: self.commit_date = self.gh.repos.get_latest_release().published_at\n",
    "    except HTTP404NotFoundError: self.commit_date = '2000-01-01T00:00:004Z'\n",
    "    res = f\"\\n## {self.cfg.version}\\n\"\n",
    "    issues = self._issue_groups()\n",
    "    res += '\\n'.join(_issues_txt(*o) for o in zip(issues, self.groups.values()))\n",
    "    if debug: return res\n",
    "    res = self.changefile.read_text().replace(marker, marker+res+\"\\n\")\n",
    "    shutil.copy(self.changefile, self.changefile.with_suffix(\".bak\"))\n",
    "    self.changefile.write_text(res)\n",
    "    run(f'git add {self.changefile}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "rel = Release()\n",
    "# print(rel.changelog(debug=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def release(self:Release):\n",
    "    \"Tag and create a release in GitHub for the current version\"\n",
    "    ver = self.cfg.version\n",
    "    notes = self.latest_notes()\n",
    "    self.gh.create_release(ver, branch=self.cfg.branch, body=notes)\n",
    "    return ver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This uses the version information from your `settings.ini`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@patch\n",
    "def latest_notes(self:Release):\n",
    "    \"Latest CHANGELOG entry\"\n",
    "    if not self.changefile.exists(): return ''\n",
    "    its = re.split(r'^## ', self.changefile.read_text(), flags=re.MULTILINE)\n",
    "    if not len(its)>0: return ''\n",
    "    return '\\n'.join(its[1].splitlines()[1:]).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All relevant pull requests and issues are fetched from the GitHub API, and are categorized according to a user-supplied mapping from labels to markdown headings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLI functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "def changelog(\n",
    "    debug:store_true=False,  # Print info to be added to CHANGELOG, instead of updating file\n",
    "    repo:str=None,  # repo to use instead of `lib_name` from `settings.ini`\n",
    "):\n",
    "    \"Create a CHANGELOG.md file from closed and labeled GitHub issues\"\n",
    "    res = Release(repo=repo).changelog(debug=debug)\n",
    "    if debug: print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "def release_git(\n",
    "    token:str=None  # Optional GitHub token (otherwise `token` file is used)\n",
    "):\n",
    "    \"Tag and create a release in GitHub for the current version\"\n",
    "    ver = Release(token=token).release()\n",
    "    print(f\"Released {ver}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "def release_gh(\n",
    "    token:str=None  # Optional GitHub token (otherwise `token` file is used)\n",
    "):\n",
    "    \"Calls `nbdev_changelog`, lets you edit the result, then pushes to git and calls `nbdev_release_git`\"\n",
    "    cfg = _find_config()\n",
    "    Release().changelog()\n",
    "    subprocess.run([os.environ.get('EDITOR','nano'), cfg.config_path/'CHANGELOG.md'])\n",
    "    if not input(\"Make release now? (y/n) \").lower().startswith('y'): sys.exit(1)\n",
    "    run('git commit -am release')\n",
    "    run('git push')\n",
    "    ver = Release(token=token).release()\n",
    "    print(f\"Released {ver}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore.all import *\n",
    "from nbdev.config import *\n",
    "from nbdev.cli import *\n",
    "\n",
    "import yaml,subprocess,glob,platform\n",
    "from os import system\n",
    "try: from packaging.version import parse\n",
    "except ImportError: from pip._vendor.packaging.version import parse\n",
    "\n",
    "_PYPI_URL = 'https://pypi.org/pypi/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def pypi_json(s):\n",
    "    \"Dictionary decoded JSON for PYPI path `s`\"\n",
    "    return urljson(f'{_PYPI_URL}{s}/json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def latest_pypi(name):\n",
    "    \"Latest version of `name` on pypi\"\n",
    "    return max(parse(r) for r,o in pypi_json(name)['releases'].items()\n",
    "               if not parse(r).is_prerelease and not nested_idx(o, 0, 'yanked'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def pypi_details(name):\n",
    "    \"Version, URL, and SHA256 for `name` from pypi\"\n",
    "    ver = str(latest_pypi(name))\n",
    "    pypi = pypi_json(f'{name}/{ver}')\n",
    "    rel = [o for o in pypi['urls'] if o['packagetype']=='sdist'][0]\n",
    "    return ver,rel['url'],rel['digests']['sha256']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import shlex\n",
    "from subprocess import Popen, PIPE, CalledProcessError\n",
    "\n",
    "def _run(cmd):\n",
    "    res = \"\"\n",
    "    with Popen(shlex.split(cmd), stdout=PIPE, bufsize=1, text=True, encoding=\"utf-8\") as p:\n",
    "        for line in p.stdout:\n",
    "            print(line, end='')\n",
    "            res += line\n",
    "\n",
    "    if p.returncode != 0: raise CalledProcessError(p.returncode, p.args)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def conda_output_path(name, build='build'):\n",
    "    \"Output path for conda build\"\n",
    "    return run(f'conda {build} --output {name}').strip().replace('\\\\', '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _write_yaml(path, name, d1, d2):\n",
    "    path = Path(path)\n",
    "    p = path/name\n",
    "    p.mkdir(exist_ok=True, parents=True)\n",
    "    yaml.SafeDumper.ignore_aliases = lambda *args : True\n",
    "    with (p/'meta.yaml').open('w', encoding=\"utf-8\") as f:\n",
    "        yaml.safe_dump(d1, f)\n",
    "        yaml.safe_dump(d2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _get_conda_meta():\n",
    "    cfg = get_config()\n",
    "    name,ver = cfg.lib_name,cfg.version\n",
    "    url = cfg.doc_host or cfg.git_url\n",
    "\n",
    "    doc_url = (cfg.doc_host + cfg.doc_baseurl) if (cfg.doc_host and cfg.doc_baseurl) else url\n",
    "    dev_url = cfg.git_url if cfg.git_url else url\n",
    "\n",
    "    hostreqs = ['pip', 'packaging', f'python >={cfg.min_python}']\n",
    "    if cfg.get('requirements'): reqs = hostreqs[-1:] + cfg.requirements.split()\n",
    "    if cfg.get('conda_requirements'): reqs += cfg.conda_requirements.split()\n",
    "\n",
    "    pypi = pypi_json(f'{name}/{ver}')\n",
    "    rel = [o for o in pypi['urls'] if o['packagetype']=='sdist'][0]\n",
    "\n",
    "    # Work around conda build bug - 'package' and 'source' must be first\n",
    "    d1 = {\n",
    "        'package': {'name': name, 'version': ver},\n",
    "        'source': {'url':rel['url'], 'sha256':rel['digests']['sha256']}\n",
    "    }\n",
    "\n",
    "    _dir = cfg.lib_path.parent\n",
    "    readme = _dir/'README.md'\n",
    "    descr = readme.read_text() if readme.exists() else ''\n",
    "    d2 = {\n",
    "        'build': {'number': '0', 'noarch': 'python',\n",
    "                  'script': '{{ PYTHON }} -m pip install . -vv'},\n",
    "        'requirements': {'host':hostreqs, 'run':reqs},\n",
    "        'test': {'imports': [cfg.lib_path.name]},\n",
    "        'about': {\n",
    "            'license': 'Apache Software',\n",
    "            'license_family': 'APACHE',\n",
    "            'home': dev_url, 'doc_url': doc_url, 'dev_url': dev_url,\n",
    "            'summary': cfg.get('description'),\n",
    "            'description': descr\n",
    "        },\n",
    "        'extra': {'recipe-maintainers': [cfg.get('user')]}\n",
    "    }\n",
    "    return name,d1,d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def write_conda_meta(path='conda'):\n",
    "    \"Writes a `meta.yaml` file to the `conda` directory of the current directory\"\n",
    "    _write_yaml(path, *_get_conda_meta())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is used in the `conda_package` CLI command.\n",
    "\n",
    "**NB**: you need to first of all upload your package to PyPi, before creating the conda package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# This function is used as a utility for creating HF spaces.\n",
    "def write_requirements(directory=None):\n",
    "    \"Writes a `requirements.txt` file to `directory` based on settings.ini.\"\n",
    "    cfg = get_config()\n",
    "    d = Path(directory) if directory else cfg.config_path\n",
    "    req = '\\n'.join([cfg.get(k, '').replace(' ', '\\n') for k in ['requirements', 'pip_requirements']])\n",
    "    (d/'requirements.txt').mk_write(req)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function can be used in situations where you need to generate a `requirements.txt` file for a project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def anaconda_upload(name, loc=None, user=None, token=None, env_token=None):\n",
    "    \"Upload `name` to anaconda\"\n",
    "    user = f'-u {user} ' if user else ''\n",
    "    if env_token: token = os.getenv(env_token)\n",
    "    token = f'-t {token} ' if token else ''\n",
    "    if not loc: loc = conda_output_path(name)\n",
    "    if not loc: raise Exception(\"Failed to find output\")\n",
    "    return _run(f'anaconda {token} upload {user} {loc} --skip-existing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.xtras import globtastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@call_parse\n",
    "def release_conda(\n",
    "    path:str='conda', # Path where package will be created\n",
    "    do_build:bool_arg=True,  # Run `conda build` step\n",
    "    build_args:str='',  # Additional args (as str) to send to `conda build`\n",
    "    skip_upload:store_true=False,  # Skip `anaconda upload` step\n",
    "    mambabuild:store_true=False,  # Use `mambabuild` (requires `boa`)\n",
    "    upload_user:str=None  # Optional user to upload package to\n",
    "):\n",
    "    \"Create a `meta.yaml` file ready to be built into a package, and optionally build and upload it\"\n",
    "    name = get_config().lib_name\n",
    "    write_conda_meta(path)\n",
    "    out = f\"Done. Next steps:\\n```\\ncd {path}\\n\"\"\"\n",
    "    os.chdir(path)\n",
    "    build = 'mambabuild' if mambabuild else 'build'\n",
    "    if not do_build: return print(f\"{out}conda {build} {name}\")\n",
    "\n",
    "    for f in globtastic('out', file_glob='*.tar.bz2'): os.remove(f)\n",
    "    cmd = f\"conda {build} --output-folder out --no-anaconda-upload {build_args} {name}\"\n",
    "    print(cmd)\n",
    "    res = _run(cmd)\n",
    "    outs = globtastic('out', file_glob='*.tar.bz2')\n",
    "    assert len(outs)==1\n",
    "    loc = outs[0]\n",
    "    if skip_upload: return print(loc)\n",
    "    if not upload_user: upload_user = get_config().conda_user\n",
    "    if not upload_user: return print(\"`conda_user` not in settings.ini and no `upload_user` passed. Cannot upload\")\n",
    "    if 'anaconda upload' not in res: return print(f\"{res}\\n\\Failed. Check auto-upload not set in .condarc. Try `--do_build False`.\")\n",
    "    return anaconda_upload(name, loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def chk_conda_rel(\n",
    "    nm:str,  # Package name on pypi\n",
    "    apkg:str=None,  # Anaconda Package (defaults to {nm})\n",
    "    channel:str='fastai',  # Anaconda Channel\n",
    "    force:store_true=False  # Always return github tag\n",
    "):\n",
    "    \"Prints GitHub tag only if a newer release exists on Pypi compared to an Anaconda Repo.\"\n",
    "    if not apkg: apkg=nm\n",
    "    condavs = L(loads(run(f'mamba repoquery search {apkg} -c {channel} --json'))['result']['pkgs'])\n",
    "    condatag = condavs.attrgot('version').map(parse)\n",
    "    pypitag = latest_pypi(nm)\n",
    "    if force or not condatag or pypitag > max(condatag): return f'{pypitag}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build and upload a conda package, cd to the root of your repo, and then:\n",
    "\n",
    "    nbdev_conda_package\n",
    "\n",
    "Or to do things more manually:\n",
    "\n",
    "```\n",
    "nbdev_conda_package --do_build false\n",
    "cd conda\n",
    "conda build --no-anaconda-upload --output-folder build {name}\n",
    "anaconda upload build/noarch/{name}-{ver}-*.tar.bz2\n",
    "```\n",
    "\n",
    "Add `--debug` to the `conda build command` to debug any problems that occur. Note that the build step takes a few minutes. Add `-u {org_name}` to the `anaconda upload` command if you wish to upload to an organization, or pass `upload_user` to `nbdev_conda_package`.\n",
    "\n",
    "**NB**: you need to first of all upload your package to PyPi, before creating the conda package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def release_pypi(\n",
    "    repository:str=\"pypi\" # Respository to upload to (defined in ~/.pypirc)\n",
    "):\n",
    "    \"Create and upload Python package to PyPI\"\n",
    "    _dir = get_config().lib_path.parent\n",
    "    system(f'cd {_dir}  && rm -rf dist build && python setup.py sdist bdist_wheel')\n",
    "    system(f'twine upload --repository {repository} {_dir}/dist/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `--repository` flag to upload to [TestPypi](https://test.pypi.org/) (e.g. `nbdev_pypi --repository testpypi`) and custom/private repositories. \n",
    "\n",
    "The [~/.pypirc](https://packaging.python.org/en/latest/specifications/pypirc/) file can be updated to configure the additional repositories, see example below:\n",
    "\n",
    "```toml\n",
    "[distutils]\n",
    "index-servers =\n",
    "    pypi\n",
    "    testpypi\n",
    "    private-repository\n",
    "\n",
    "[pypi]\n",
    "username = __token__\n",
    "password = <PyPI token>\n",
    "\n",
    "[testpypi]\n",
    "username = __token__\n",
    "password = <TestPyPI token>\n",
    "\n",
    "[private-repository]\n",
    "repository = <private-repository URL>\n",
    "username = <private-repository username>\n",
    "password = <private-repository password>\n",
    "```\n",
    "\n",
    "Use `nbdev_pypi --repository private-repository` to upload to the private repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def release_both(\n",
    "    path:str='conda', # Path where package will be created\n",
    "    do_build:bool_arg=True,  # Run `conda build` step\n",
    "    build_args:str='',  # Additional args (as str) to send to `conda build`\n",
    "    skip_upload:store_true=False,  # Skip `anaconda upload` step\n",
    "    mambabuild:store_true=False,  # Use `mambabuild` (requires `boa`)\n",
    "    upload_user:str=None,  # Optional user to upload package to\n",
    "    repository:str=\"pypi\" # Pypi respository to upload to (defined in ~/.pypirc)\n",
    "):\n",
    "    \"Release both conda and PyPI packages\"\n",
    "    release_pypi.__wrapped__(repository)\n",
    "    release_conda.__wrapped__(path, do_build=do_build, build_args=build_args, skip_upload=skip_upload, mambabuild=mambabuild, upload_user=upload_user)\n",
    "    nbdev_bump_version.__wrapped__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bump Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def bump_version(version, part=2, unbump=False):\n",
    "    version = version.split('.')\n",
    "    incr = -1 if unbump else 1\n",
    "    version[part] = str(int(version[part]) + incr)\n",
    "    for i in range(part+1, 3): version[i] = '0'\n",
    "    return '.'.join(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def nbdev_bump_version(\n",
    "    part:int=2,  # Part of version to bump\n",
    "    unbump:bool=False):  # Reduce version instead of increasing it\n",
    "    \"Increment version in settings.ini by one\"\n",
    "    cfg = get_config()\n",
    "    print(f'Old version: {cfg.version}')\n",
    "    cfg.d['version'] = bump_version(get_config().version, part, unbump=unbump)\n",
    "    cfg.save()\n",
    "    update_version()\n",
    "    nbdev_export.__wrapped__()\n",
    "    print(f'New version: {cfg.version}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
